# TODO Cloud - Tests et am√©liorations quellog

**Objectif** : Tester et am√©liorer quellog avec des logs PostgreSQL r√©els issus des 3 plateformes cloud manag√©es (GCP Cloud SQL, AWS RDS, Azure Database).

**Statut CLI** : ‚úÖ GCP, AWS, Azure op√©rationnels

---

## üéØ Phase 1 - Cr√©ation d'instances de test

### GCP Cloud SQL
- [ ] Cr√©er instance PostgreSQL 15/16 (tier `db-f1-micro` pour √©conomiser)
- [ ] Configurer les logs : `log_statement = 'all'`, `log_duration = on`, `log_checkpoints = on`
- [ ] Activer Cloud Logging pour r√©cup√©ration automatique
- [ ] Tester les formats de logs : stderr vs jsonPayload

**Commandes** :
```bash
# Cr√©ation instance
gcloud sql instances create quellog-test-pg \
  --database-version=POSTGRES_16 \
  --tier=db-f1-micro \
  --region=europe-west1 \
  --database-flags=log_statement=all,log_duration=on,log_checkpoints=on \
  --project=serious-ascent-478222-c9

# R√©cup√©ration logs
gcloud logging read "resource.type=cloudsql_database" \
  --project=serious-ascent-478222-c9 \
  --format=json > gcp_cloudsql_logs.json
```

### AWS RDS PostgreSQL
- [ ] Cr√©er instance PostgreSQL 16 (classe `db.t3.micro` free tier)
- [ ] Activer Enhanced Monitoring
- [ ] Configurer Parameter Group avec logging verbeux
- [ ] Tester r√©cup√©ration logs via `aws rds download-db-log-file-portion`

**Commandes** :
```bash
# Cr√©ation instance
aws rds create-db-instance \
  --db-instance-identifier quellog-test-pg \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --engine-version 16.6 \
  --master-username postgres \
  --master-user-password 'TestQuellog2025!' \
  --allocated-storage 20 \
  --region eu-west-3

# Lister logs disponibles
aws rds describe-db-log-files --db-instance-identifier quellog-test-pg --region eu-west-3

# T√©l√©charger logs
aws rds download-db-log-file-portion \
  --db-instance-identifier quellog-test-pg \
  --log-file-name error/postgresql.log \
  --region eu-west-3 \
  --output text > aws_rds_logs.log
```

### Azure Database for PostgreSQL
- [ ] Cr√©er Flexible Server PostgreSQL 16
- [ ] Configurer Server Parameters pour logging
- [ ] Activer diagnostic logs
- [ ] Tester `az postgres flexible-server server-logs download`

**Commandes** :
```bash
# Cr√©ation resource group
az group create --name quellog-test-rg --location francecentral

# Cr√©ation instance
az postgres flexible-server create \
  --name quellog-test-pg \
  --resource-group quellog-test-rg \
  --location francecentral \
  --admin-user pgadmin \
  --admin-password 'TestQuellog2025!' \
  --sku-name Standard_B1ms \
  --tier Burstable \
  --version 16

# Lister logs
az postgres flexible-server server-logs list \
  --name quellog-test-pg \
  --resource-group quellog-test-rg

# T√©l√©charger logs
az postgres flexible-server server-logs download \
  --name quellog-test-pg \
  --resource-group quellog-test-rg \
  --name postgresql-2025-11-17_000000.log
```

---

## üß™ Phase 2 - G√©n√©ration de workload test

### Sc√©narios de test
- [ ] **Workload OLTP** : Beaucoup d'INSERT/UPDATE/DELETE rapides
- [ ] **Workload OLAP** : Requ√™tes analytiques longues avec agr√©gations
- [ ] **Workload mixte** : Mix lecture/√©criture
- [ ] **Stress test** : Connexions multiples, transactions concurrentes
- [ ] **Maintenance** : VACUUM, ANALYZE, REINDEX, CHECKPOINT forc√©s

### Scripts de g√©n√©ration
```bash
# pgbench standard
pgbench -i -s 10 postgres://user@host/db
pgbench -c 10 -j 2 -t 1000 postgres://user@host/db

# Requ√™tes complexes custom
psql -h <host> -U postgres -c "
  SELECT pg_sleep(5);  -- Requ√™te lente
  VACUUM ANALYZE;       -- Maintenance
  CREATE INDEX ...;     -- DDL
"
```

**√Ä g√©n√©rer** :
- [ ] Script `generate_oltp_workload.sh`
- [ ] Script `generate_olap_workload.sh`
- [ ] Script `generate_maintenance_events.sh`
- [ ] Script `generate_errors.sh` (connexions √©chou√©es, deadlocks, etc.)

---

## üìä Phase 3 - Tests formats de logs sp√©cifiques cloud

### GCP Cloud SQL
- [ ] Format JSON natif de Cloud Logging (jsonPayload)
- [ ] Logs stderr classiques
- [ ] Logs avec metadata GCP (project_id, instance_id, etc.)
- [ ] Tester parsing de `protoPayload` pour les op√©rations admin

**Sp√©cificit√©s √† tester** :
- Champs GCP : `resource.labels.database_id`, `severity`, `timestamp`
- Logs d'audit (connexions, CREATE/DROP DATABASE)
- Slow query logs dans Cloud Monitoring

### AWS RDS
- [ ] Format CSV (via Enhanced Monitoring)
- [ ] Format stderr standard
- [ ] Logs CloudWatch integration
- [ ] Performance Insights logs

**Sp√©cificit√©s √† tester** :
- Logs splitt√©s par heure (`postgresql.log.2025-11-17-10`, etc.)
- Logs compress√©s (`.gz`)
- Rotation automatique des logs
- Enhanced Monitoring JSON

### Azure Database
- [ ] Format syslog
- [ ] Diagnostic logs (JSON)
- [ ] Logs via Azure Monitor
- [ ] Log Analytics integration

**Sp√©cificit√©s √† tester** :
- Logs avec `_ResourceId`, `OperationName`
- Integration avec Kusto Query Language (KQL)
- Server logs vs diagnostic logs

---

## üîß Phase 4 - Am√©liorations quellog

### Support formats cloud (d√©tection automatique)
- [ ] **Auto-d√©tection format GCP** : Reconna√Ætre JSON Cloud Logging (jsonPayload, severity, resource)
- [ ] **Auto-d√©tection format AWS** : Reconna√Ætre Enhanced Monitoring JSON, logs CSV
- [ ] **Auto-d√©tection format Azure** : Reconna√Ætre syslog + metadata Azure (_ResourceId, OperationName)
- [ ] **Extraction automatique metadata cloud** : instance_id, r√©gion, projet, resource_id

### üåä Streaming depuis le cloud (PRIORITAIRE)

**Concept** : Au lieu de t√©l√©charger puis analyser, streamer directement depuis les APIs cloud vers quellog.

#### GCP Cloud Logging ‚Üí quellog
```bash
# Stream en temps r√©el
gcloud logging read "resource.type=cloudsql_database" \
  --format=json \
  --project=serious-ascent-478222-c9 \
  --freshness=1d | quellog --stdin --format=gcp-json

# Avec filtre temporel
gcloud logging read "resource.type=cloudsql_database AND timestamp>=\"2025-11-17T00:00:00Z\"" \
  --format=json --project=serious-ascent-478222-c9 | quellog --stdin
```

**Impl√©mentation** :
- [ ] Ajouter flag `--stdin` pour lire depuis stdin
- [ ] Parser JSON array stream√© (logs viennent ligne par ligne)
- [ ] Extraire `jsonPayload.message` ou `textPayload` selon le type
- [ ] Parser metadata : `resource.labels.database_id`, `severity`, `timestamp`

#### AWS CloudWatch Logs / RDS ‚Üí quellog
```bash
# Stream logs RDS en temps r√©el
aws logs tail /aws/rds/instance/quellog-test-pg/postgresql \
  --follow \
  --format short | quellog --stdin

# Ou via RDS API (pagination automatique)
aws rds download-db-log-file-portion \
  --db-instance-identifier quellog-test-pg \
  --log-file-name error/postgresql.log \
  --output text \
  --region eu-west-3 | quellog --stdin
```

**Impl√©mentation** :
- [ ] Support streaming ligne par ligne (pas besoin de tout buffer)
- [ ] G√©rer les logs splitt√©s par heure automatiquement
- [ ] D√©tecter Enhanced Monitoring JSON vs logs text

#### Azure Monitor ‚Üí quellog
```bash
# Stream depuis Log Analytics
az monitor log-analytics query \
  --workspace <workspace-id> \
  --analytics-query "AzureDiagnostics | where ResourceType == 'POSTGRESQL'" \
  --output json | quellog --stdin --format=azure-json

# Stream depuis server logs
az postgres flexible-server server-logs download \
  --name quellog-test-pg \
  --resource-group quellog-test-rg \
  --name postgresql.log --output none | quellog --stdin
```

**Impl√©mentation** :
- [ ] Parser JSON Log Analytics (tables, colonnes dynamiques)
- [ ] Extraire `Message_s` ou `RawData` selon la query
- [ ] Support syslog format natif Azure

### Avantages du streaming
‚úÖ **Pas de t√©l√©chargement** : Analyse directe, √©conomie disque
‚úÖ **Temps r√©el** : Possibilit√© de `--follow` pour monitoring live
‚úÖ **Efficace** : Traitement incr√©mental, pas besoin de tout charger en RAM
‚úÖ **S√©curit√©** : Logs jamais stock√©s localement
‚úÖ **Int√©gration native** : Utilise les APIs/CLI officielles

### Difficult√© d'impl√©mentation : üü¢ FACILE

**Pourquoi c'est simple** :
- Go a d√©j√† `os.Stdin` natif
- Parsers existants lisent ligne par ligne (d√©j√† streamable)
- Les CLIs cloud supportent `--output text` ou `--format json` vers stdout
- Juste besoin d'ajouter un check : si `filename == "-"` ou flag `--stdin` ‚Üí lire depuis stdin

**Changements minimes** :
```go
// Dans cmd/root.go
rootCmd.PersistentFlags().Bool("stdin", false, "Read logs from stdin")

// Dans cmd/execute.go
func executeParsing(cmd *cobra.Command, args []string) {
    if useStdin {
        // Parse from os.Stdin instead of files
        parser.ParseReader(os.Stdin, out)
    } else {
        // Existing file parsing logic
    }
}
```

**POC en 1h max** ! üöÄ

### üìù Features essentielles √† impl√©menter

#### 1. Support stdin
- [ ] Flag `--stdin` ou accepter `"-"` comme filename
- [ ] Lire depuis `os.Stdin` au lieu d'un fichier
- [ ] Support pipe : `gcloud logging read ... | quellog --stdin`
- [ ] D√©tection automatique du format depuis stdin (JSON, CSV, text)

#### 2. Time ranges standards (√† la cloud CLI)
- [ ] Flag `--last` avec dur√©es standards : `1h`, `24h`, `7d`, `30d`
- [ ] Syntaxe intuitive : `quellog --last=1h` au lieu de `--begin "2025-11-17 21:00:00"`
- [ ] Mapping automatique vers --begin/--end

**Exemples d'utilisation** :
```bash
# Derni√®re heure
quellog --last=1h logs.json
gcloud logging read ... --freshness=1h | quellog --stdin --last=1h

# Dernier jour
quellog --last=24h /var/log/postgresql/*.log

# Derni√®re semaine
quellog --last=7d archive.tar.gz

# Dernier mois
quellog --last=30d /path/to/logs/
```

**Standards √† supporter** :
- `1h`, `2h`, `6h`, `12h`, `24h` (heures)
- `1d`, `7d`, `30d`, `90d` (jours)
- `1w`, `2w`, `4w` (semaines)
- `1m`, `3m`, `6m`, `12m` (mois approximatifs : 30j)

**Impl√©mentation** :
```go
// Parse --last flag et convertir en begin/end
func parseLastDuration(last string) (begin, end time.Time) {
    duration, err := time.ParseDuration(last) // Go supporte "1h", "24h"
    if err != nil {
        // G√©rer "7d", "30d" manuellement
        duration = parseCustomDuration(last)
    }
    end = time.Now()
    begin = end.Add(-duration)
    return begin, end
}
```

**Priorit√©** : üî¥ **HAUTE** - Am√©liore drastiquement l'UX pour les logs cloud

### Nouvelles features cloud
- [ ] **Extraction metadata cloud** : Afficher instance_id, r√©gion, projet dans le summary
- [ ] **Support logs compress√©s cloud** : `.gz` splitt√©s par heure (AWS)
- [ ] **Filter par severity cloud** : Map `INFO/WARNING/ERROR` ‚Üí log levels PostgreSQL
- [ ] **Timeline cloud events** : Afficher backups, failovers, maintenance windows

### Optimisations
- [ ] Parser streaming incr√©mental (pas besoin de tout lire d'un coup)
- [ ] Support logs multi-fichiers horodat√©s (AWS : `postgresql.log.2025-11-*`)
- [ ] Agr√©gation cross-instance (analyser plusieurs instances √† la fois)
- [ ] Export vers formats cloud natives (BigQuery, CloudWatch Insights, Log Analytics)

---

## üìà Phase 5 - Benchmarks & Comparaisons

### Performance quellog vs outils cloud
- [ ] Comparer avec `gcloud logging read` (vitesse, features)
- [ ] Comparer avec AWS CloudWatch Insights
- [ ] Comparer avec Azure Log Analytics
- [ ] Comparer avec pgBadger sur logs cloud

### M√©triques √† mesurer
- [ ] Temps de parsing pour 1GB, 10GB, 100GB de logs
- [ ] M√©moire utilis√©e
- [ ] Pr√©cision des analyses (SQL queries d√©tect√©es, erreurs, etc.)
- [ ] Features manquantes vs outils cloud natifs

### Datasets de test
- [ ] **Small** : 100MB de logs (1h de prod l√©g√®re)
- [ ] **Medium** : 1GB de logs (1 jour de prod normale)
- [ ] **Large** : 10GB de logs (1 semaine de prod intense)
- [ ] **XLarge** : 100GB+ (1 mois de prod multi-instance)

---

## üöÄ Phase 6 - Automation & CI/CD

### Scripts d'automatisation
- [ ] `cloud_test_suite.sh` : D√©ploie instances sur les 3 clouds, g√©n√®re workload, r√©cup√®re logs, analyse
- [ ] `compare_clouds.sh` : Compare les formats/logs des 3 providers
- [ ] `stress_test.sh` : G√©n√®re 100GB de logs et mesure perfs quellog

### GitHub Actions
- [ ] Workflow hebdomadaire : D√©ploie instances cloud, teste quellog, cleanup
- [ ] Tests de r√©gression sur logs cloud r√©els
- [ ] Badges avec support "GCP ‚úÖ AWS ‚úÖ Azure ‚úÖ"

### Documentation
- [ ] `docs/cloud-providers.md` : Guide d'utilisation avec GCP/AWS/Azure
- [ ] `docs/cloud-log-formats.md` : Sp√©cificit√©s de chaque format cloud
- [ ] Exemples dans README : Comment analyser logs GCP/AWS/Azure

---

## üí° Id√©es avanc√©es

### Int√©grations cloud natives
- [ ] Publier quellog comme Cloud Run service (GCP)
- [ ] Lambda function (AWS) pour analyse √† la vol√©e
- [ ] Azure Function pour processing de logs
- [ ] Container image optimis√© pour Cloud environments

### Analyse pr√©dictive
- [ ] D√©tecter patterns d'incidents dans logs cloud
- [ ] Alerting sur anomalies (spike de slow queries, erreurs inhabituelles)
- [ ] Correlation avec m√©triques cloud (CPU, RAM, IOPS)

### Export & Visualisation
- [ ] Export vers BigQuery pour analytics SQL
- [ ] Export vers CloudWatch dashboard
- [ ] Export vers Azure Workbooks
- [ ] Grafana datasource plugin

---

## üóìÔ∏è Planning sugg√©r√©

### Session 1 (Dimanche) - Setup & Discovery
- Cr√©er 1 instance sur chaque cloud (GCP, AWS, Azure)
- G√©n√©rer du workload basique (pgbench)
- Streamer premiers logs vers quellog (tester le pipe)
- Identifier les diff√©rences de formats

### Session 2 - Streaming & Time ranges
- **Impl√©menter support `--stdin`** (priorit√© haute)
- **Impl√©menter flag `--last`** (1h, 24h, 7d, 30d, etc.)
- Auto-d√©tection format JSON GCP (jsonPayload)
- Auto-d√©tection format AWS (text vs JSON)
- Auto-d√©tection format Azure (syslog + metadata)
- Cr√©er tests unitaires

### Session 3 - Features & Optimisations
- Extraction automatique metadata cloud
- Support streaming incr√©mental (pas de buffer total)
- Timeline cloud events (backups, failovers)
- Tests de performance streaming vs download

### Session 4 - Automation
- Scripts de test automatis√©s
- Benchmarks vs outils natifs
- Documentation compl√®te
- Cleanup & optimisations finales

---

## üìù Notes & Contraintes

### Co√ªts cloud (estimation)
- **GCP** : db-f1-micro ~$7/mois (free tier possible)
- **AWS** : db.t3.micro free tier 750h/mois (gratuit 1√®re ann√©e)
- **Azure** : B1ms ~$12/mois (free tier 12 mois)

**üí° Astuce** : Toujours supprimer les instances apr√®s tests pour √©viter les frais !

### Commandes de cleanup
```bash
# GCP
gcloud sql instances delete quellog-test-pg --project=serious-ascent-478222-c9

# AWS
aws rds delete-db-instance --db-instance-identifier quellog-test-pg --skip-final-snapshot --region eu-west-3

# Azure
az group delete --name quellog-test-rg --yes
```

---

**Pr√™t pour dimanche ! üöÄ**
